{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 5\n",
    "NUM_THREADS = 4\n",
    "k_batchsize = 0  #yes, can be greater than num samples!\n",
    "                 #gotta figure out for yourself how many times you want to see the same data\n",
    "\n",
    "# Generating some simple data\n",
    "# create 1000 random samples, each is a 1D array from the normal distribution (10, 1)\n",
    "# each vector has 4 dimensions in this example\n",
    "data = 10 * np.random.randn(N_SAMPLES, 4) + 1\n",
    "# create 1000 random labels of 0 and 1\n",
    "target = np.random.randint(0, 2, size=N_SAMPLES)\n",
    "\n",
    "# Create queue types specified for data and target, shapes specified (4D and scalar)\n",
    "queue = tf.FIFOQueue(capacity=50, dtypes=[tf.float32, tf.int32], shapes=[[4], []])\n",
    "\n",
    "enqueue_op = queue.enqueue_many([data, target])\n",
    "#=======================================================\n",
    "if (k_batchsize > 0) :\n",
    "    dequeue_op = queue.dequeue_many(k_batchsize) #batch_size at a time, in a list\n",
    "else :\n",
    "    dequeue_op = queue.dequeue() #one at a time, not in a list\n",
    "#=======================================================\n",
    "\n",
    "# create NUM_THREADS to do enqueue\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * NUM_THREADS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------  step: 0\n",
      "data_batch tf.shape is Tensor(\"Shape:0\", shape=(1,), dtype=int32)\n",
      "data size is 4\n",
      "1\n",
      "[ 8.20465088 -4.16747808  1.97255611 -6.28378201]\n",
      "------  step: 1\n",
      "data_batch tf.shape is Tensor(\"Shape_1:0\", shape=(1,), dtype=int32)\n",
      "data size is 4\n",
      "1\n",
      "[ -9.21293449  -1.14715385  -7.73651648  13.16541767]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    \n",
    "    for step in xrange(2): \n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        data_batch, label_batch = sess.run(dequeue_op)\n",
    "        print('------  step: ' + str(step))\n",
    "        print('data_batch tf.shape is ' + str(tf.shape(data_batch))) \n",
    "        if (k_batchsize > 0) :\n",
    "            print('batch size is ' + str(data_batch.shape[0])) # (rows, colums)\n",
    "            print('data size is ' + str(data_batch.shape[1])) #the length of a column\n",
    "        else:\n",
    "            print('data size is ' + str(data_batch.shape[0]))\n",
    "        print label_batch\n",
    "        print data_batch\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tflow2]",
   "language": "python",
   "name": "conda-env-tflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

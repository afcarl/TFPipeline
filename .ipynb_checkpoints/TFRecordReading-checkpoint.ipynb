{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import spectreader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_THREADS = 4\n",
    "k_nepochs=1\n",
    "k_batchsize = 5\n",
    "k_nbatches = 2\n",
    "k_shownum = 3 # limits the number of images displayed\n",
    "\n",
    "# data dependent parameters\n",
    "k_nClass=2\n",
    "height=256\n",
    "width=856\n",
    "\n",
    "#Reads data from the prepaired file of TFRecords\n",
    "def getImage(fname) :\n",
    "  label, image = spectreader.getImage(fname)\n",
    "  print('GLOBAL getImage: image tf.shape is ' + str(tf.shape(image))) \n",
    "  print('GLOBAL getImage: image get_shape is ' + str(image.get_shape().as_list())) # [None, None, 1] where 1 is num channels (though it should not be since images were already B&W!!!!)\n",
    "\n",
    "  #image=tf.reshape(tf.image.rgb_to_grayscale(image),[height*width]) #We are already in B&W\n",
    "  image=tf.reshape(image,[height*width])\n",
    "  \n",
    "  # re-define label as a \"one-hot\" vector \n",
    "  # it will be [0,1] or [1,0] here. \n",
    "  # This approach can easily be extended to more classes.\n",
    "  label=tf.stack(tf.one_hot(label-1, k_nClass))\n",
    "  return label, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getImage data/train-00000-of-00001\n",
      "getImage: filenameQ.get_shape is Tensor(\"input_producer_2_Size:0\", shape=(), dtype=int32)\n",
      "getImage: returning tensor with shape Tensor(\"Shape_4:0\", shape=(3,), dtype=int32)\n",
      "getImage: returning tensor with x.get_shape().as_list() [None, None, 1]\n",
      "GLOBAL getImage: image tf.shape is Tensor(\"Shape_5:0\", shape=(3,), dtype=int32)\n",
      "GLOBAL getImage: image get_shape is [None, None, 1]\n"
     ]
    }
   ],
   "source": [
    "# This runs without a session, but sets up several ops for the graph.\n",
    "# This function does *not* get called during the session (as I understand it)!\n",
    "target, data = getImage(\"data/train-00000-of-00001\", k_nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageBatch, labelBatch = tf.train.shuffle_batch(\n",
    "    [data, target], batch_size=k_batchsize,\n",
    "    num_threads=NUM_THREADS,\n",
    "    \n",
    "    enqueue_many=False, #IMPORTANT to get right, default=False\n",
    "    capacity=10,  #1000,\n",
    "    min_after_dequeue=5) #500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------  step: 0\n",
      "data_batch tf.shape is Tensor(\"Shape_6:0\", shape=(2,), dtype=int32)\n",
      "batch size is 5\n",
      "data size is 219136\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "------  step: 1\n",
      "data_batch tf.shape is Tensor(\"Shape_7:0\", shape=(2,), dtype=int32)\n",
      "batch size is 5\n",
      "data size is 219136\n",
      "[[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    #!!! need this line if there is a num_epochs other than none in getImage string_input_producer\n",
    "    sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    \n",
    "    # Create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    #XX  enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    enqueue_threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    \n",
    "    shownum=0\n",
    "    \n",
    "    for step in xrange(k_nbatches): \n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        #XX  data_batch, label_batch = sess.run(dequeue_op)\n",
    "        data_batch, label_batch = sess.run([imageBatch, labelBatch])\n",
    "        \n",
    "        print('------  step: ' + str(step))\n",
    "        print('data_batch tf.shape is ' + str(tf.shape(data_batch))) # 2, its a 2D array\n",
    "        print('batch size is ' + str(data_batch.shape[0])) # (rows, colums)\n",
    "        print('data size is ' + str(data_batch.shape[1])) #the length of a column\n",
    "        print label_batch\n",
    "        #print data_batch\n",
    "\n",
    "        for i in range(k_batchsize) :\n",
    "            if shownum < k_shownum :\n",
    "                foo=Image.fromarray(np.reshape(data_batch[i]*255, (height, width)))\n",
    "                foo.show()\n",
    "                shownum += 1\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tflow2]",
   "language": "python",
   "name": "conda-env-tflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
